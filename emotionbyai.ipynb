{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanka23052307/emotionbyai/blob/main/emotionbyai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVFcN7Obj7bF",
        "outputId": "7162a329-8d83-4697-a8ad-40c18c826f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile emotionbyAI.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "import os\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "\n",
        "\n",
        "    /* Style the container of the main content */\n",
        "    .css-1d391kg {\n",
        "        background-color: rgba(255, 255, 255, 0.8); /* White background with slight transparency */\n",
        "        border-radius: 15px;\n",
        "        padding: 20px;\n",
        "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "    }\n",
        "\n",
        "\n",
        "    /* Style the labels and values */\n",
        "\n",
        "    .st-emotion-cache-1s2v671 {\n",
        "          font-size: 2.875rem;\n",
        "          color: #ff4b4b;\n",
        "    }\n",
        "    .st-emotion-cache-br351g {\n",
        "        font-size: 1.5rem;\n",
        "        color: #ff4b4b;\n",
        "    }\n",
        "    .st-emotion-cache-1gulkj5{\n",
        "        font-size: 22px;\n",
        "        color: #ff4b4b;\n",
        "    }\n",
        "    .st-emotion-cache-ue6h4q {\n",
        "            color: white;\n",
        "    }\n",
        "    .st-ay {\n",
        "        font-size: 0.8rem;\n",
        "    }\n",
        "    .st-b6{\n",
        "        color:#ff4b4b\n",
        "    }\n",
        "    .st-bc {\n",
        "        height: 2.0rem !important;\n",
        "    }\n",
        "    .st-bi {\n",
        "        color: #ff4b4b;\n",
        "    }\n",
        "    h1 {\n",
        "        color: #049489;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .st-emotion-cache-1r4qj8v{\n",
        "        color: #ff4b4b;\n",
        "    }\n",
        "    .output{\n",
        "        color:white;\n",
        "    }\n",
        "    .st-c3{\n",
        "        color: rgb(255, 75, 75);\n",
        "    }\n",
        "    .emotion-output{\n",
        "      font-size:2.0rem;\n",
        "    }\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"<h1>Emotion by AI</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "# 1. Add the uploader (restrict to image types if you like)\n",
        "uploaded_file = st.file_uploader(\n",
        "    label=\"Choose an image\",\n",
        "    type=[\"png\", \"jpg\", \"jpeg\"],\n",
        "    help=\"Upload a .png, .jpg, or .jpeg file\"\n",
        ")\n",
        "\n",
        "# 2. Once they upload, open it with PIL\n",
        "if uploaded_file is not None:\n",
        "    # PIL.Image can read from the file-like object directly\n",
        "    image = Image.open(uploaded_file)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "        ])\n",
        "\n",
        "    img = transform(image).unsqueeze(0)\n",
        "\n",
        "    model=models.resnet50(pretrained=True)\n",
        "    features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, 7)\n",
        "        )\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/data/ds/EmotionDetectionR50.pth', map_location='cpu'))\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(img)                 # shape: [1, num_classes]\n",
        "      probs   = torch.softmax(outputs, dim=1)\n",
        "      pred_ix = probs.argmax(dim=1).item()\n",
        "\n",
        "    class_names = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Neutral\",\"Sad\",\"Surprise\"]\n",
        "    st.markdown(\n",
        "    f'<div class=\"emotion-output\">'\n",
        "    f'Predicted emotion: <strong>{class_names[pred_ix]}</strong> â€” confidence 67%.'\n",
        "    f'</div>',\n",
        "    unsafe_allow_html=True)\n",
        "    # st.markdown(f'Predicted emotion: {class_names[pred_ix]} â€” confidence 57%.', unsafe_allow_html=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PS-UyGlOkqt",
        "outputId": "3905cb4c-ee89-4d40-9772-884a6b720023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing emotionbyAI.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install --upgrade streamlit\n",
        "# run in the background, redirect logs so you can inspect them\n",
        "streamlit run emotionbyAI.py \\\n",
        "  --server.port 8501 \\\n",
        "  --server.address 0.0.0.0 \\\n",
        "  --server.headless true \\\n",
        "  --server.enableCORS false \\\n",
        "  &> streamlit.log &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSNB0-fbNpQ1",
        "outputId": "97e2f0ad-4f88-4d30-d3b7-466aa0a0e68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.2/10.2 MB 37.1 MB/s eta 0:00:00\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.9/6.9 MB 58.1 MB/s eta 0:00:00\n",
            "Installing collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is anything listening on 8501?\n",
        "!lsof -iTCP:8501 -sTCP:LISTEN\n",
        "# Or just look at the tail of the log\n",
        "!tail -n 20 streamlit.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3_Dh5IaOQeo",
        "outputId": "40e276ce-779a-48db-d79c-1b0f0b68fb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "streamlit 767 root    6u  IPv4  33144      0t0  TCP *:8501 (LISTEN)\n",
            "2025-11-03 19:36:52.503 \n",
            "Warning: the config option 'server.enableCORS=false' is not compatible with\n",
            "'server.enableXsrfProtection=true'.\n",
            "As a result, 'server.enableCORS' is being overridden to 'true'.\n",
            "\n",
            "More information:\n",
            "In order to protect against CSRF attacks, we send a cookie with each request.\n",
            "To do so, we must specify allowable origins, which places a restriction on\n",
            "cross-origin resource sharing.\n",
            "\n",
            "If cross origin resource sharing is required, please disable server.enableXsrfProtection.\n",
            "            \n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  URL: http://0.0.0.0:8501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill the ngrok process and tear down all tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# authenticate (replace with YOUR token)\n",
        "ngrok.set_auth_token(\"2x5nxInMgn8SjN2uRcLP5Le6fUD_82w1qyfsqxHPByzLGBHe3\")\n",
        "\n",
        "# start your Streamlit app\n",
        "!nohup streamlit run emotionbyAI.py &\n",
        "\n",
        "# open a tunnel on 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸš€ Live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fxjBaIpLi6D",
        "outputId": "e9ac1d79-78d0-4ec5-ef27-89086dfb3356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.1\n",
            "nohup: appending output to 'nohup.out'\n",
            "ðŸš€ Live at: NgrokTunnel: \"https://06d2f8cbe5f7.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f ngrok-stable-linux-amd64.zip  # if you want to clean up old zip first\n",
        "!wget -q https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -oq ngrok-stable-linux-amd64.zip\n",
        "!rm -f ngrok            # remove any old binary\n",
        "!wget -q https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -q ngrok-stable-linux-amd64.zip\n",
        "!./ngrok authtoken 2x5nxInMgn8SjN2uRcLP5Le6fUD_82w1qyfsqxHPByzLGBHe3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQuejWHdxue",
        "outputId": "489a0f8f-e1d6-4ec4-d361-5272a3ad045d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n_ho2i_scHJ",
        "outputId": "15267824-c23a-45c2-d3cf-425e1be9edd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but PCA was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # For progress bar\n",
        "import pickle\n",
        "# dir_path=\"/content/drive/MyDrive/features\"\n",
        "# directory_csv = os.path.dirname(dir_path)\n",
        "\n",
        "# # Create the directory if it doesn't exist\n",
        "# if not os.path.exists(directory_csv):\n",
        "#     os.makedirs(directory_csv)\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# List to store features\n",
        "all_features = []\n",
        "\n",
        "# Process each image\n",
        "# image_path = os.path.join(\"/content/\", \"image\")\n",
        "image_cv = cv2.imread(\"PrivateTest_552501.jpg\")\n",
        "\n",
        "# Process the image with MediaPipe\n",
        "result = face_mesh.process(image_cv)\n",
        "\n",
        "# Extract landmarks if found\n",
        "if result.multi_face_landmarks:\n",
        "  for face_landmarks in result.multi_face_landmarks:\n",
        "    # Extract the 468 landmarks (x, y, z coordinates)\n",
        "    features = []\n",
        "    for landmark in face_landmarks.landmark:\n",
        "      features.extend([landmark.x, landmark.y, landmark.z])  # Add x, y, z coordinates\n",
        "\n",
        "    # Append features with image filename\n",
        "    all_features.append([image] + features)\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "columns = ['image'] + [f'point_{i}_{axis}' for i in range(468) for axis in ['x', 'y', 'z']]\n",
        "df = pd.DataFrame(all_features, columns=columns)\n",
        "\n",
        "x=df.drop(\"image\",axis=1)\n",
        "\n",
        "with open('/content/drive/MyDrive/data/ds/pca.pkl', 'rb') as f:\n",
        "    pca = pickle.load(f)\n",
        "x_reduced=pca.transform(x)\n",
        "\n",
        "x_tensor=torch.tensor(x_reduced,dtype=torch.float32)\n",
        "\n",
        "class EmotionDetection(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(EmotionDetection, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model=EmotionDetection(input_dim=x_reduced.shape[1])\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/data/ds/EmotionDetectionMediapipe.pth', map_location='cpu'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(x_tensor)                 # shape: [1, num_classes]\n",
        "    probs   = torch.softmax(outputs, dim=1)\n",
        "    pred_ix = probs.argmax(dim=1).item()\n",
        "\n",
        "class_names = os.listdir('/content/drive/MyDrive/data/train_1')\n",
        "print(class_names[pred_ix])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIpCvFf0gkYl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfEZlBZ7C9NJ"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/data/train_1 /content/train_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "0lzz48ZK4UbP",
        "outputId": "052f9f02-e168-401e-de69-92ff8eb0b7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping cv2 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: opencv-python 4.11.0.86\n",
            "Uninstalling opencv-python-4.11.0.86:\n",
            "  Successfully uninstalled opencv-python-4.11.0.86\n",
            "Found existing installation: opencv-python-headless 4.11.0.86\n",
            "Uninstalling opencv-python-headless-4.11.0.86:\n",
            "  Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4efee6bfc98a46af8ff54aeaa971e5c0",
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Remove any bogus packages\n",
        "!pip uninstall -y cv2 opencv-python opencv-python-headless\n",
        "\n",
        "# Install the official OpenCV-Python\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5-pI0m6r3v0",
        "outputId": "f18ed83f-1ad7-42f9-d844-ba800fe1a2c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.6500759878419453\n",
            "Test Precision prediction:0.6500759878419453\n",
            "Test Recall prediction:0.6500759878419453\n",
            "Test f1-score prediction:0.6500759878419453\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "#resnet18\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(),  # Augment\n",
        "    transforms.RandomRotation(15),  # Augment\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Augment\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Augment\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "train_data=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/data/train_1',transform=transform)\n",
        "\n",
        "angry_class_idx = train_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(train_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 376, replace=False)\n",
        "\n",
        "disgust_class_idx = train_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(train_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 376, replace=False)\n",
        "\n",
        "fear_class_idx = train_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(train_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 376, replace=False)\n",
        "\n",
        "happy_class_idx = train_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(train_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 376, replace=False)\n",
        "\n",
        "neutral_class_idx = train_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(train_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 376, replace=False)\n",
        "\n",
        "sad_class_idx = train_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(train_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 376, replace=False)\n",
        "\n",
        "surprise_class_idx = train_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(train_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 376, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "train_data = Subset(train_data, random_indices)\n",
        "train_dataloader=DataLoader(train_data,batch_size=32,shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "model=models.resnet18(pretrained=True)\n",
        "\n",
        "# âœ… 4. Load Pretrained ResNet-50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… 5. Freeze Most Layers, Train Last Block\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# âœ… 6. Modify Final Layer for 7 Classes\n",
        "features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "epoch=10\n",
        "model.to(device)\n",
        "\n",
        "for i in range(epoch):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in train_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ONnIk7z7R0g",
        "outputId": "0d7e5234-16d9-44e2-ebab-b9dd1e1ddb2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.5122265122265123\n",
            "Test Precision prediction:0.5122265122265123\n",
            "Test Recall prediction:0.5122265122265123\n",
            "Test f1-score prediction:0.5122265122265123\n"
          ]
        }
      ],
      "source": [
        "#Resnet18 Testdata\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import numpy as np\n",
        "\n",
        "transform=torchvision.transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((224, 224)),  # Ensure consistent input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_data=datasets.ImageFolder(root='/content/drive/MyDrive/data/test_1',transform=transform)\n",
        "\n",
        "# Angry:958\n",
        "# Disgust:111\n",
        "# fear:1024\n",
        "# happy:1774\n",
        "# neutral:1233\n",
        "# sad:1247\n",
        "# surprise:831\n",
        "\n",
        "angry_class_idx = test_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(test_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 111, replace=False)\n",
        "\n",
        "disgust_class_idx = test_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(test_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 111, replace=False)\n",
        "\n",
        "fear_class_idx = test_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(test_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 111, replace=False)\n",
        "\n",
        "happy_class_idx = test_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(test_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 111, replace=False)\n",
        "\n",
        "neutral_class_idx = test_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(test_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 111, replace=False)\n",
        "\n",
        "sad_class_idx = test_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(test_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 111, replace=False)\n",
        "\n",
        "surprise_class_idx = test_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(test_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 111, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "print(len(random_indices))\n",
        "test_data = Subset(test_data, random_indices)\n",
        "\n",
        "test_dataloader=DataLoader(test_data,batch_size=16,shuffle=True,num_workers=4,pin_memory=True)\n",
        "\n",
        "model=models.resnet18(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "features=model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"EmotionDetection.pth\"))\n",
        "model.to(device)\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total=0\n",
        "    correct=0\n",
        "    for inputs,targets in test_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs=model(inputs)\n",
        "        _,predicted=torch.max(outputs,1)\n",
        "        preds,targets=predicted.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqMiAyLAFInK",
        "outputId": "dae71d30-fc1d-4f49-8696-d98310a5529c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.6363981762917933\n",
            "Test Precision prediction:0.6363981762917933\n",
            "Test Recall prediction:0.6363981762917933\n",
            "Test f1-score prediction:0.6363981762917933\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "#resnet34\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(),  # Augment\n",
        "    transforms.RandomRotation(15),  # Augment\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Augment\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Augment\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "train_data=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/data/train_1',transform=transform)\n",
        "\n",
        "angry_class_idx = train_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(train_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 376, replace=False)\n",
        "\n",
        "disgust_class_idx = train_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(train_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 376, replace=False)\n",
        "\n",
        "fear_class_idx = train_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(train_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 376, replace=False)\n",
        "\n",
        "happy_class_idx = train_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(train_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 376, replace=False)\n",
        "\n",
        "neutral_class_idx = train_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(train_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 376, replace=False)\n",
        "\n",
        "sad_class_idx = train_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(train_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 376, replace=False)\n",
        "\n",
        "surprise_class_idx = train_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(train_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 376, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "train_data = Subset(train_data, random_indices)\n",
        "train_dataloader=DataLoader(train_data,batch_size=32,shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "model=models.resnet34(pretrained=True)\n",
        "\n",
        "# âœ… 4. Load Pretrained ResNet-50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… 5. Freeze Most Layers, Train Last Block\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# âœ… 6. Modify Final Layer for 7 Classes\n",
        "features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "epoch=10\n",
        "model.to(device)\n",
        "for i in range(epoch):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in train_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frLefPcoJx-K",
        "outputId": "a04ed097-1de5-45dd-a16f-643904d060bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.5186615186615187\n",
            "Test Precision prediction:0.5186615186615187\n",
            "Test Recall prediction:0.5186615186615187\n",
            "Test f1-score prediction:0.5186615186615187\n"
          ]
        }
      ],
      "source": [
        "#Resnet34 Testdata\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import numpy as np\n",
        "\n",
        "transform=torchvision.transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((224, 224)),  # Ensure consistent input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_data=datasets.ImageFolder(root='/content/drive/MyDrive/data/test_1',transform=transform)\n",
        "\n",
        "# Angry:958\n",
        "# Disgust:111\n",
        "# fear:1024\n",
        "# happy:1774\n",
        "# neutral:1233\n",
        "# sad:1247\n",
        "# surprise:831\n",
        "\n",
        "angry_class_idx = test_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(test_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 111, replace=False)\n",
        "\n",
        "disgust_class_idx = test_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(test_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 111, replace=False)\n",
        "\n",
        "fear_class_idx = test_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(test_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 111, replace=False)\n",
        "\n",
        "happy_class_idx = test_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(test_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 111, replace=False)\n",
        "\n",
        "neutral_class_idx = test_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(test_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 111, replace=False)\n",
        "\n",
        "sad_class_idx = test_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(test_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 111, replace=False)\n",
        "\n",
        "surprise_class_idx = test_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(test_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 111, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "print(len(random_indices))\n",
        "test_data = Subset(test_data, random_indices)\n",
        "\n",
        "test_dataloader=DataLoader(test_data,batch_size=16,shuffle=True,num_workers=4,pin_memory=True)\n",
        "\n",
        "model=models.resnet34(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "features=model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"EmotionDetection.pth\"))\n",
        "model.to(device)\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total=0\n",
        "    correct=0\n",
        "    for inputs,targets in test_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs=model(inputs)\n",
        "        _,predicted=torch.max(outputs,1)\n",
        "        preds,targets=predicted.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3sq4eDpngZw",
        "outputId": "e2062e39-e493-43f9-89dd-b95946afc938"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:02<00:00, 228MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.7207446808510638\n",
            "Test Precision prediction:0.7207446808510638\n",
            "Test Recall prediction:0.7207446808510638\n",
            "Test f1-score prediction:0.7207446808510638\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "#vgg\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(),  # Augment\n",
        "    transforms.RandomRotation(15),  # Augment\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Augment\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Augment\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "\n",
        "])\n",
        "train_data=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/data/train_1',transform=transform)\n",
        "\n",
        "angry_class_idx = train_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(train_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 376, replace=False)\n",
        "\n",
        "disgust_class_idx = train_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(train_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 376, replace=False)\n",
        "\n",
        "fear_class_idx = train_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(train_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 376, replace=False)\n",
        "\n",
        "happy_class_idx = train_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(train_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 376, replace=False)\n",
        "\n",
        "neutral_class_idx = train_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(train_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 376, replace=False)\n",
        "\n",
        "sad_class_idx = train_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(train_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 376, replace=False)\n",
        "\n",
        "surprise_class_idx = train_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(train_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 376, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "train_data = Subset(train_data, random_indices)\n",
        "\n",
        "train_dataloader=DataLoader(train_data,batch_size=16,shuffle=True,num_workers=4,pin_memory=True)\n",
        "\n",
        "model=models.vgg16(pretrained=True)\n",
        "\n",
        "# âœ… 4. Load Pretrained ResNet-50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "features=model.classifier[-1].in_features\n",
        "model.classifier[-1]=nn.Linear(features,7)\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "epoch=20\n",
        "model.to(device)\n",
        "for i in range(epoch):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in train_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXh8dCI4YrGB",
        "outputId": "0287f7a7-a95c-434b-e846-9ba4ef0d43ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.5431145431145431\n",
            "Test Precision prediction:0.5431145431145431\n",
            "Test Recall prediction:0.5431145431145431\n",
            "Test f1-score prediction:0.5431145431145431\n"
          ]
        }
      ],
      "source": [
        "#vgg Testdata\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import numpy as np\n",
        "\n",
        "transform=torchvision.transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((224, 224)),  # Ensure consistent input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_data=datasets.ImageFolder(root='/content/drive/MyDrive/data/test_1',transform=transform)\n",
        "\n",
        "# Angry:958\n",
        "# Disgust:111\n",
        "# fear:1024\n",
        "# happy:1774\n",
        "# neutral:1233\n",
        "# sad:1247\n",
        "# surprise:831\n",
        "\n",
        "angry_class_idx = test_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(test_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 111, replace=False)\n",
        "\n",
        "disgust_class_idx = test_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(test_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 111, replace=False)\n",
        "\n",
        "fear_class_idx = test_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(test_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 111, replace=False)\n",
        "\n",
        "happy_class_idx = test_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(test_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 111, replace=False)\n",
        "\n",
        "neutral_class_idx = test_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(test_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 111, replace=False)\n",
        "\n",
        "sad_class_idx = test_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(test_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 111, replace=False)\n",
        "\n",
        "surprise_class_idx = test_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(test_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 111, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "print(len(random_indices))\n",
        "test_data = Subset(test_data, random_indices)\n",
        "\n",
        "test_dataloader=DataLoader(test_data,batch_size=16,shuffle=True,num_workers=4,pin_memory=True)\n",
        "\n",
        "model=models.vgg16(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "features=model.classifier[-1].in_features\n",
        "model.classifier[-1]=nn.Linear(features,7)\n",
        "\n",
        "model.load_state_dict(torch.load(\"EmotionDetection.pth\"))\n",
        "model.to(device)\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total=0\n",
        "    correct=0\n",
        "    for inputs,targets in test_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs=model(inputs)\n",
        "        _,predicted=torch.max(outputs,1)\n",
        "        preds,targets=predicted.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-wGxQESDTpK",
        "outputId": "ebe55920-f6b3-464a-aa1e-e00e14d32dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 225MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy prediction:0.7120060790273556\n",
            "Test Precision prediction:0.7120060790273556\n",
            "Test Recall prediction:0.7120060790273556\n",
            "Test f1-score prediction:0.7120060790273556\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "#resnet50\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(),  # Augment\n",
        "    transforms.RandomRotation(15),  # Augment\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Augment\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Augment\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "train_data=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/data/train_1',transform=transform)\n",
        "\n",
        "angry_class_idx = train_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(train_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 376, replace=False)\n",
        "\n",
        "disgust_class_idx = train_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(train_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 376, replace=False)\n",
        "\n",
        "fear_class_idx = train_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(train_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 376, replace=False)\n",
        "\n",
        "happy_class_idx = train_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(train_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 376, replace=False)\n",
        "\n",
        "neutral_class_idx = train_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(train_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 376, replace=False)\n",
        "\n",
        "sad_class_idx = train_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(train_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 376, replace=False)\n",
        "\n",
        "surprise_class_idx = train_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(train_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 376, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "train_data = Subset(train_data, random_indices)\n",
        "train_dataloader=DataLoader(train_data,batch_size=32,shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "model=models.resnet50(pretrained=True)\n",
        "\n",
        "# âœ… 4. Load Pretrained ResNet-50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… 5. Freeze Most Layers, Train Last Block\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# âœ… 6. Modify Final Layer for 7 Classes\n",
        "features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-3, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "epoch=40\n",
        "model.to(device)\n",
        "for i in range(epoch):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in train_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
        "    scheduler.step(epoch_loss)\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6vzqqTgsmcL",
        "outputId": "a17a515f-2208-4fdd-c907-de18c12edee0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 212MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.1705\n",
            "Test Accuracy prediction:0.20185714285714285\n",
            "Test Accuracy prediction:0.2342857142857143\n",
            "Test Accuracy prediction:0.2606428571428571\n",
            "Test Accuracy prediction:0.29542857142857143\n",
            "Test Accuracy prediction:0.32092857142857145\n",
            "Test Accuracy prediction:0.3447142857142857\n",
            "Test Accuracy prediction:0.37585714285714283\n",
            "Test Accuracy prediction:0.3945\n",
            "Test Accuracy prediction:0.4142142857142857\n",
            "Test Accuracy prediction:0.43192857142857144\n",
            "Test Accuracy prediction:0.44392857142857145\n",
            "Test Accuracy prediction:0.45107142857142857\n",
            "Test Accuracy prediction:0.4610714285714286\n",
            "Test Accuracy prediction:0.4724285714285714\n",
            "Test Accuracy prediction:0.483\n",
            "Test Accuracy prediction:0.4860714285714286\n",
            "Test Accuracy prediction:0.5007142857142857\n",
            "Test Accuracy prediction:0.5122857142857142\n",
            "Test Accuracy prediction:0.5138571428571429\n",
            "Test Accuracy prediction:0.5232142857142857\n",
            "Test Accuracy prediction:0.5330714285714285\n",
            "Test Accuracy prediction:0.5338571428571428\n",
            "Test Accuracy prediction:0.5392142857142858\n",
            "Test Accuracy prediction:0.5444285714285715\n",
            "Test Accuracy prediction:0.5561428571428572\n",
            "Test Accuracy prediction:0.5601428571428572\n",
            "Test Accuracy prediction:0.5675714285714286\n",
            "Test Accuracy prediction:0.5726428571428571\n",
            "Test Accuracy prediction:0.5707142857142857\n",
            "Test Accuracy prediction:0.5707142857142857\n",
            "Test Precision prediction:0.5496035733806331\n",
            "Test Recall prediction:0.5707142857142857\n",
            "Test f1-score prediction:0.5519105931874262\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "#resnet50\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "import random\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(),  # Augment\n",
        "    transforms.RandomRotation(15),  # Augment\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Augment\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Augment\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "train_data=torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/data/train_1',transform=transform)\n",
        "def oversample_dataset(dataset):\n",
        "    \"\"\"\n",
        "    Oversample each class so that each class has the same number of samples as the class with the maximum count.\n",
        "    \"\"\"\n",
        "    labels = np.array(dataset.targets)\n",
        "    unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
        "    #max_count = np.max(class_counts)\n",
        "    max_count=2000\n",
        "\n",
        "    oversampled_indices = []\n",
        "    for cls in unique_classes:\n",
        "        # Get indices of all samples of this class.\n",
        "        cls_indices = np.where(labels == cls)[0]\n",
        "        # Randomly sample indices with replacement to match max_count.\n",
        "        replicated_indices = np.random.choice(cls_indices, size=max_count, replace=True)\n",
        "        oversampled_indices.extend(replicated_indices)\n",
        "    # Shuffle the list of oversampled indices to mix classes\n",
        "    random.shuffle(oversampled_indices)\n",
        "    return Subset(dataset, oversampled_indices)\n",
        "\n",
        "# Create an oversampled dataset and corresponding DataLoader:\n",
        "oversampled_dataset = oversample_dataset(train_data)\n",
        "train_dataloader=DataLoader(oversampled_dataset,batch_size=32,shuffle=True,num_workers=4,pin_memory=True,persistent_workers=True)\n",
        "\n",
        "model=models.resnet50(pretrained=True)\n",
        "\n",
        "# âœ… 4. Load Pretrained ResNet-50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… 5. Freeze Most Layers, Train Last Block\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# for param in model.layer4.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# âœ… 6. Modify Final Layer for 7 Classes\n",
        "features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-4, weight_decay=0)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "epochs=30\n",
        "model.to(device)\n",
        "\n",
        "for p in model.parameters():\n",
        "  p.requires_grad=True\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in train_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
        "    print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='macro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WJU612UMh9p",
        "outputId": "5d0f8da4-d69c-4e54-c522-8bc5a0e4b8fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 205MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:Test Accuracy prediction:0.5140896582953081\n",
            "1:Test Accuracy prediction:0.6167752272806437\n",
            "2:Test Accuracy prediction:0.656588526246125\n",
            "3:Test Accuracy prediction:0.6750844682852067\n",
            "4:Test Accuracy prediction:0.6869274443554286\n",
            "5:Test Accuracy prediction:0.6995715629245185\n",
            "6:Test Accuracy prediction:0.7166742136612212\n",
            "7:Test Accuracy prediction:0.7240238252812706\n",
            "8:Test Accuracy prediction:0.7367724406980389\n",
            "9:Test Accuracy prediction:0.7419972830819603\n",
            "Train Accuracy prediction:0.7419972830819603\n",
            "Train Precision prediction:0.7398022028538165\n",
            "Train Recall prediction:0.7419407351329299\n",
            "Train f1-score prediction:0.7401021874186424\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms,models\n",
        "from torch import nn,optim\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "\n",
        "# 1. Prepare your dataset as before\n",
        "transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "train_data = datasets.ImageFolder(root='/content/drive/MyDrive/data/train_1', transform=transform)\n",
        "\n",
        "# 2. Compute per-sample weights\n",
        "labels = np.array(train_data.targets)                  # shape (N,)\n",
        "class_counts = np.bincount(labels)                     # shape (num_classes,)\n",
        "class_weights = 1.0 / class_counts                     # weight for each class\n",
        "sample_weights = class_weights[labels]                  # weight per sample\n",
        "\n",
        "# 3. Create the sampler\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# 4. Plug into your DataLoader (drop shuffle=True!)\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    sampler=sampler,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "model=models.resnet50(pretrained=True)\n",
        "\n",
        "# âœ… 4. Load Pretrained ResNet-50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… 5. Freeze Most Layers, Train Last Block\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# for param in model.layer4.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# âœ… 6. Modify Final Layer for 7 Classes\n",
        "features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-4, weight_decay=0)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "epochs=10\n",
        "model.to(device)\n",
        "\n",
        "for p in model.parameters():\n",
        "  p.requires_grad=True\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"{epoch}:Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "print(f\"Train Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Train Precision prediction:{precision_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Train Recall prediction:{recall_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Train f1-score prediction:{f1_score(all_labels,all_preds, average='macro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka4cmviRHONd",
        "outputId": "d224740f-e55b-42f0-f97f-d0dfa2a56202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "777\n",
            "Test Accuracy prediction:0.5727155727155727\n",
            "Test Precision prediction:0.5727155727155727\n",
            "Test Recall prediction:0.5727155727155727\n",
            "Test f1-score prediction:0.5727155727155727\n"
          ]
        }
      ],
      "source": [
        "#Resnet50 Testdata\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import numpy as np\n",
        "\n",
        "transform=torchvision.transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((224, 224)),  # Ensure consistent input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_data=datasets.ImageFolder(root='/content/drive/MyDrive/data/test_1',transform=transform)\n",
        "\n",
        "# Angry:958\n",
        "# Disgust:111\n",
        "# fear:1024\n",
        "# happy:1774\n",
        "# neutral:1233\n",
        "# sad:1247\n",
        "# surprise:831\n",
        "\n",
        "angry_class_idx = test_data.class_to_idx['angry']\n",
        "angry_targets=np.where(np.array(test_data.targets) == angry_class_idx)[0]\n",
        "angry_indices = np.random.choice(angry_targets, 111, replace=False)\n",
        "\n",
        "disgust_class_idx = test_data.class_to_idx['disgust']\n",
        "disgust_targets=np.where(np.array(test_data.targets) == disgust_class_idx)[0]\n",
        "disgust_indices = np.random.choice(disgust_targets, 111, replace=False)\n",
        "\n",
        "fear_class_idx = test_data.class_to_idx['fear']\n",
        "fear_targets=np.where(np.array(test_data.targets) == fear_class_idx)[0]\n",
        "fear_indices = np.random.choice(fear_targets, 111, replace=False)\n",
        "\n",
        "happy_class_idx = test_data.class_to_idx['happy']\n",
        "happy_targets=np.where(np.array(test_data.targets) == happy_class_idx)[0]\n",
        "happy_indices = np.random.choice(happy_targets, 111, replace=False)\n",
        "\n",
        "neutral_class_idx = test_data.class_to_idx['neutral']\n",
        "neutral_targets=np.where(np.array(test_data.targets) == neutral_class_idx)[0]\n",
        "neutral_indices = np.random.choice(neutral_targets, 111, replace=False)\n",
        "\n",
        "sad_class_idx = test_data.class_to_idx['sad']\n",
        "sad_targets=np.where(np.array(test_data.targets) == sad_class_idx)[0]\n",
        "sad_indices = np.random.choice(sad_targets, 111, replace=False)\n",
        "\n",
        "surprise_class_idx = test_data.class_to_idx['surprise']\n",
        "surprise_targets=np.where(np.array(test_data.targets) == surprise_class_idx)[0]\n",
        "surprise_indices = np.random.choice(surprise_targets, 111, replace=False)\n",
        "\n",
        "random_indices=np.concatenate((angry_indices,disgust_indices,fear_indices,happy_indices,neutral_indices,sad_indices,surprise_indices),axis=0)\n",
        "print(len(random_indices))\n",
        "test_data = Subset(test_data, random_indices)\n",
        "\n",
        "test_dataloader=DataLoader(test_data,batch_size=16,shuffle=True,num_workers=4,pin_memory=True)\n",
        "\n",
        "model=models.resnet50(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "features=model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"EmotionDetection.pth\"))\n",
        "model.to(device)\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total=0\n",
        "    correct=0\n",
        "    for inputs,targets in test_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs=model(inputs)\n",
        "        _,predicted=torch.max(outputs,1)\n",
        "        preds,targets=predicted.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='micro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='micro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYgbuJIwlmor",
        "outputId": "28b1a2f3-6136-47ea-e95c-d20c74e68564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[455  19 100  14  78  75   9]\n",
            " [111 545  15  29  22  24   4]\n",
            " [ 79   9 331  11 108 128  84]\n",
            " [ 12   2   9 658  33  12  24]\n",
            " [ 51   4  34  38 527  80  16]\n",
            " [ 98   7  72  27 168 366  12]\n",
            " [ 21   0  42  25  16   8 638]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.55      0.61      0.58       750\n",
            "     Disgust       0.93      0.73      0.82       750\n",
            "        fear       0.55      0.44      0.49       750\n",
            "       happy       0.82      0.88      0.85       750\n",
            "     neutral       0.55      0.70      0.62       750\n",
            "         sad       0.53      0.49      0.51       750\n",
            "    surprise       0.81      0.85      0.83       750\n",
            "\n",
            "    accuracy                           0.67      5250\n",
            "   macro avg       0.68      0.67      0.67      5250\n",
            "weighted avg       0.68      0.67      0.67      5250\n",
            "\n",
            "Test Accuracy prediction:0.6704761904761904\n",
            "Test Precision prediction:0.6774242632179431\n",
            "Test Recall prediction:0.6704761904761904\n",
            "Test f1-score prediction:0.66955301950373\n"
          ]
        }
      ],
      "source": [
        "#Resnet50 Testdata\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import random\n",
        "\n",
        "transform=torchvision.transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((224, 224)),  # Ensure consistent input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_data=datasets.ImageFolder(root='/content/drive/MyDrive/data/test_1',transform=transform)\n",
        "class_names=[\"Angry\",\"Disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
        "# Angry:958\n",
        "# Disgust:111\n",
        "# fear:1024\n",
        "# happy:1774\n",
        "# neutral:1233\n",
        "# sad:1247\n",
        "# surprise:831\n",
        "\n",
        "def oversample_dataset(dataset):\n",
        "    \"\"\"\n",
        "    Oversample each class so that each class has the same number of samples as the class with the maximum count.\n",
        "    \"\"\"\n",
        "    labels = np.array(dataset.targets)\n",
        "    unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
        "    #max_count = np.max(class_counts)\n",
        "    max_count=750\n",
        "\n",
        "    oversampled_indices = []\n",
        "    for cls in unique_classes:\n",
        "        # Get indices of all samples of this class.\n",
        "        cls_indices = np.where(labels == cls)[0]\n",
        "        # Randomly sample indices with replacement to match max_count.\n",
        "        replicated_indices = np.random.choice(cls_indices, size=max_count, replace=True)\n",
        "        oversampled_indices.extend(replicated_indices)\n",
        "    # Shuffle the list of oversampled indices to mix classes\n",
        "    random.shuffle(oversampled_indices)\n",
        "    return Subset(dataset, oversampled_indices)\n",
        "\n",
        "# Create an oversampled dataset and corresponding DataLoader:\n",
        "oversampled_dataset = oversample_dataset(test_data)\n",
        "print(len(oversampled_dataset))\n",
        "test_dataloader=DataLoader(oversampled_dataset,batch_size=16,shuffle=True,num_workers=4,pin_memory=True,persistent_workers=True)\n",
        "\n",
        "\n",
        "model=models.resnet50(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "features=model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"EmotionDetection.pth\"))\n",
        "model.to(device)\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total=0\n",
        "    correct=0\n",
        "    for inputs,targets in test_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs=model(inputs)\n",
        "        _,predicted=torch.max(outputs,1)\n",
        "        preds,targets=predicted.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "\n",
        "print(confusion_matrix(all_labels, all_preds))\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='macro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Bb8ilHlYOQ90",
        "outputId": "30301351-1185-4e6b-a12e-64db8a1da104"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediapipe'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2c778541f98e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m  \u001b[0;31m# For progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "# Paths\n",
        "input_folder = \"/content/drive/MyDrive/data/train_1/angry\"  # Folder containing images\n",
        "dir_path=\"/content/drive/MyDrive/extracted/angry/features.csv\"\n",
        "directory_csv = os.path.dirname(dir_path)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(directory_csv):\n",
        "    os.makedirs(directory_csv)\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# List to store features\n",
        "all_features = []\n",
        "\n",
        "# Process each image\n",
        "image_files = [f for f in os.listdir(input_folder)]\n",
        "\n",
        "for image_file in tqdm(image_files, desc=\"Extracting Features\"):\n",
        "    image_path = os.path.join(input_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Process the image with MediaPipe\n",
        "    result = face_mesh.process(image)\n",
        "\n",
        "    # Extract landmarks if found\n",
        "    if result.multi_face_landmarks:\n",
        "        for face_landmarks in result.multi_face_landmarks:\n",
        "            # Extract the 468 landmarks (x, y, z coordinates)\n",
        "            features = []\n",
        "            for landmark in face_landmarks.landmark:\n",
        "                features.extend([landmark.x, landmark.y, landmark.z])  # Add x, y, z coordinates\n",
        "\n",
        "            # Append features with image filename\n",
        "            all_features.append([image_file] + features)\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "columns = ['image'] + [f'point_{i}_{axis}' for i in range(468) for axis in ['x', 'y', 'z']]\n",
        "df = pd.DataFrame(all_features, columns=columns)\n",
        "df.to_csv(dir_path, index=False)\n",
        "\n",
        "print(f\"Features saved to {directory_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TElgiY0NIo1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "angry_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/angry/features.csv\")\n",
        "angry_df[\"emotion\"]=\"angry\"\n",
        "disgust_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/disgust/features.csv\")\n",
        "disgust_df[\"emotion\"]=\"disgust\"\n",
        "fear_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/fear/features.csv\")\n",
        "fear_df[\"emotion\"]=\"fear\"\n",
        "happy_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/happy/features.csv\")\n",
        "happy_df[\"emotion\"]=\"happy\"\n",
        "neutral_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/neutral/features.csv\")\n",
        "neutral_df[\"emotion\"]=\"neutral\"\n",
        "sad_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/sad/features.csv\")\n",
        "sad_df[\"emotion\"]=\"sad\"\n",
        "surprise_df=pd.read_csv(r\"/content/drive/MyDrive/extracted/surprise/features.csv\")\n",
        "surprise_df[\"emotion\"]=\"surprise\"\n",
        "df=pd.concat([angry_df,disgust_df,fear_df,happy_df,neutral_df,sad_df,surprise_df],axis=0)\n",
        "df.to_pickle(\"dataframe.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rh046j4Aa26"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "df=pd.read_pickle(\"dataframe.pkl\")\n",
        "x=df.drop([\"image\",\"emotion\"],axis=1)\n",
        "y=df[\"emotion\"]\n",
        "\n",
        "# Isolation Forest for outlier detection\n",
        "iso_forest = IsolationForest(n_estimators=100, contamination=0.02, random_state=42)\n",
        "outlier_preds = iso_forest.fit_predict(x)\n",
        "\n",
        "# Add predictions to dataframe\n",
        "df['outlier'] = outlier_preds\n",
        "df_clean = df[df['outlier'] == 1].drop('outlier', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efaZ493rGnwE",
        "outputId": "25acc130-82e8-4b97-d12e-7f1123416af1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:Train Accuracy prediction:0.2910496557559906\n",
            "10:Train Accuracy prediction:0.4940574637486057\n",
            "20:Train Accuracy prediction:0.5225970229624216\n",
            "30:Train Accuracy prediction:0.5457902227008731\n",
            "40:Train Accuracy prediction:0.5616369860379246\n",
            "50:Train Accuracy prediction:0.5716373706681026\n",
            "50:Train Accuracy prediction:0.5716373706681026\n",
            "Train Precision prediction:0.511164960583431\n",
            "Train Recall prediction:0.5953236817145495\n",
            "Train f1-score prediction:0.5276356098266282\n",
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim,nn\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x=df_clean.drop([\"image\",\"emotion\"],axis=1)\n",
        "y=df_clean[\"emotion\"]\n",
        "\n",
        "# smote = SMOTE()\n",
        "# x_resampled, y_resampled = smote.fit_resample(x, y)\n",
        "\n",
        "scaler=StandardScaler()\n",
        "x_scaled=scaler.fit_transform(x)\n",
        "\n",
        "with open('/content/drive/MyDrive/scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "pca=PCA(n_components=256)\n",
        "x_reduced=pca.fit_transform(x_scaled)\n",
        "with open('/content/drive/MyDrive/pca.pkl', 'wb') as f:\n",
        "    pickle.dump(pca, f)\n",
        "\n",
        "encoder=LabelEncoder()\n",
        "y_encoded=encoder.fit_transform(y)\n",
        "\n",
        "x_tensor=torch.tensor(x_reduced,dtype=torch.float32)\n",
        "y_tensor=torch.tensor(y_encoded,dtype=torch.long)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_counts = np.bincount(y_tensor.numpy())\n",
        "class_weights = 1. / class_counts\n",
        "weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "class EmotionDetection(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(EmotionDetection, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "model=EmotionDetection(input_dim=x_reduced.shape[1])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "dataset = TensorDataset(x_tensor,y_tensor)\n",
        "dataloader=DataLoader(dataset,batch_size=64,shuffle=True,num_workers=4,pin_memory=True)\n",
        "\n",
        "epoch=51\n",
        "model.to(device)\n",
        "\n",
        "for i in range(epoch):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    all_preds=[]\n",
        "    all_labels=[]\n",
        "    for inputs,targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,targets)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        preds,targets=preds.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    scheduler.step(epoch_loss)\n",
        "    if i%10==0:\n",
        "      print(f\"{i}:Train Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "\n",
        "print(f\"{i}:Train Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Train Precision prediction:{precision_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Train Recall prediction:{recall_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Train f1-score prediction:{f1_score(all_labels,all_preds, average='macro')}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"EmotionDetection.pth\")#to save the model and no need to train the model again and againprint(f\"{i}/{epoch} loss-->{running_loss}\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5nFdKr-4mhR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI9V0UEy4qHH",
        "outputId": "32b1989a-718e-45fb-9fe1-a24e41430630"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 841/841 [00:21<00:00, 39.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features saved to /content/drive/MyDrive/extracted_test/surprise\n"
          ]
        }
      ],
      "source": [
        "#mediapipe testdata\n",
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "# Paths\n",
        "input_folder = \"/content/drive/MyDrive/data/test_1/surprise\"  # Folder containing images\n",
        "dir_path=\"/content/drive/MyDrive/extracted_test/surprise/features.csv\"\n",
        "directory_csv = os.path.dirname(dir_path)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(directory_csv):\n",
        "    os.makedirs(directory_csv)\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# List to store features\n",
        "all_features = []\n",
        "\n",
        "# Process each image\n",
        "image_files = [f for f in os.listdir(input_folder)]\n",
        "\n",
        "for image_file in tqdm(image_files, desc=\"Extracting Features\"):\n",
        "    image_path = os.path.join(input_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Process the image with MediaPipe\n",
        "    result = face_mesh.process(image)\n",
        "\n",
        "    # Extract landmarks if found\n",
        "    if result.multi_face_landmarks:\n",
        "        for face_landmarks in result.multi_face_landmarks:\n",
        "            # Extract the 468 landmarks (x, y, z coordinates)\n",
        "            features = []\n",
        "            for landmark in face_landmarks.landmark:\n",
        "                features.extend([landmark.x, landmark.y, landmark.z])  # Add x, y, z coordinates\n",
        "\n",
        "            # Append features with image filename\n",
        "            all_features.append([image_file] + features)\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "columns = ['image'] + [f'point_{i}_{axis}' for i in range(468) for axis in ['x', 'y', 'z']]\n",
        "df = pd.DataFrame(all_features, columns=columns)\n",
        "df.to_csv(dir_path, index=False)\n",
        "\n",
        "print(f\"Features saved to {directory_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fep-TM_TZ5BP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "angry_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/angry/features.csv\")\n",
        "angry_df[\"emotion\"]=\"angry\"\n",
        "disgust_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/disgust/features.csv\")\n",
        "disgust_df[\"emotion\"]=\"disgust\"\n",
        "fear_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/fear/features.csv\")\n",
        "fear_df[\"emotion\"]=\"fear\"\n",
        "happy_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/happy/features.csv\")\n",
        "happy_df[\"emotion\"]=\"happy\"\n",
        "neutral_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/neutral/features.csv\")\n",
        "neutral_df[\"emotion\"]=\"neutral\"\n",
        "sad_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/sad/features.csv\")\n",
        "sad_df[\"emotion\"]=\"sad\"\n",
        "surprise_df=pd.read_csv(r\"/content/drive/MyDrive/extracted_test/surprise/features.csv\")\n",
        "surprise_df[\"emotion\"]=\"surprise\"\n",
        "df=pd.concat([angry_df,disgust_df,fear_df,happy_df,neutral_df,sad_df,surprise_df],axis=0)\n",
        "df.to_pickle(\"dataframe_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yifhr_KRxPc",
        "outputId": "320fc143-f955-4b68-a504-093aab4435c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy prediction:0.5526949713941584\n",
            "Test Precision prediction:0.4789707039154897\n",
            "Test Recall prediction:0.5463435234178886\n",
            "Test f1-score prediction:0.4903609266135435\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim,nn\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "df=pd.read_pickle(\"dataframe_test.pkl\")\n",
        "x=df.drop([\"image\",\"emotion\"],axis=1)\n",
        "y=df[\"emotion\"]\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "x_scaled=scaler.transform(x)\n",
        "\n",
        "with open('/content/drive/MyDrive/pca.pkl', 'rb') as f:\n",
        "    pca = pickle.load(f)\n",
        "x_reduced=pca.transform(x_scaled)\n",
        "\n",
        "encoder=LabelEncoder()\n",
        "y_encoded=encoder.fit_transform(y)\n",
        "\n",
        "x_tensor=torch.tensor(x_reduced,dtype=torch.float32)\n",
        "y_tensor=torch.tensor(y_encoded,dtype=torch.long)\n",
        "\n",
        "class EmotionDetection(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(EmotionDetection, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model=EmotionDetection(input_dim=x_reduced.shape[1])\n",
        "model.load_state_dict(torch.load(\"EmotionDetection.pth\"))\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-3, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataset = TensorDataset(x_tensor,y_tensor)\n",
        "test_dataloader=DataLoader(dataset,batch_size=32,shuffle=True,num_workers=4,pin_memory=True)\n",
        "model.to(device)\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total=0\n",
        "    correct=0\n",
        "    for inputs,targets in test_dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs=model(inputs)\n",
        "        _,predicted=torch.max(outputs,1)\n",
        "        preds,targets=predicted.cpu(),targets.cpu()\n",
        "        all_preds.extend(preds.numpy())  # Store predictions\n",
        "        all_labels.extend(targets.numpy())  # Store true labels\n",
        "\n",
        "print(f\"Test Accuracy prediction:{accuracy_score(all_labels,all_preds)}\")\n",
        "print(f\"Test Precision prediction:{precision_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Test Recall prediction:{recall_score(all_labels,all_preds, average='macro')}\")\n",
        "print(f\"Test f1-score prediction:{f1_score(all_labels,all_preds, average='macro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuS9FKhmTLOP",
        "outputId": "bd462845-9d78-4f09-d460-3e5e279123bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "yfinance 0.2.59 requires protobuf<6,>=5.29.0, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.7 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1rcE7cnaWGZ4HMpWnaMbXqzt3veOfblmq",
      "authorship_tag": "ABX9TyPv+0rMKcU9pP+Ilti+KcCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}